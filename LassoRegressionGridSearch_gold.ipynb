{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":807,"status":"ok","timestamp":1681719877319,"user":{"displayName":"minizy mint","userId":"14901815158738573355"},"user_tz":-420},"id":"QLi-yjfwOtcV","outputId":"9ebd8db7-17f2-4d9a-bde4-629224118c7c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameter values:  {'lasso__alpha': 0.0001}\n","Best score:  0.8924378466432591\n","MAE =  0.031572240432425146\n","MSE =  0.001721875661406321\n","RMSE =  0.04149548965136236\n","Score =  0.8834354206334446\n"]}],"source":["import pandas as pd  \n","import numpy as np  \n","import matplotlib.pyplot as plt  \n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures \n","from sklearn.model_selection import train_test_split, GridSearchCV \n","from sklearn.pipeline import make_pipeline \n","from sklearn.linear_model import Lasso\n","from sklearn import metrics\n","\n","def outlier_removal(column):\n","    # Capping the outlier rows with Percentiles\n","    upper_limit = column.quantile(.95)\n","    # set upper limit to 95percentile\n","    lower_limit = column.quantile(.05)\n","    # set lower limit to 5 percentile\n","    column.loc[(column > upper_limit)] = upper_limit\n","    column.loc[(column < lower_limit)] = lower_limit\n","    return column\n","\n","dataset=pd.read_csv(\"https://raw.githubusercontent.com/phattarin-kitbumrung/machinelearning-python/dataset/main/goldprice.csv\")\n","\n","# train & test set\n","dataset[['SPX', 'GLD', 'USO', 'EUR/USD']] = dataset[['SPX', 'GLD', 'USO', 'EUR/USD']].apply(outlier_removal)\n","# select the features and target variable\n","x = dataset.drop(['Date', 'EUR/USD'], axis=1)\n","y = dataset['EUR/USD']\n","# dividing dataset in to train test 80% - 20%\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n","\n","# Create an instance of the StandardScaler\n","scaler = StandardScaler()\n","# Fit the StandardScaler on the training dataset\n","scaler.fit(x_train)\n","# Transform the training dataset\n","# using the StandardScaler\n","x_train_scaled = scaler.transform(x_train)\n","x_test_scaled = scaler.transform(x_test)\n","\n","# Create a PolynomialFeatures object of degree 2\n","poly = PolynomialFeatures(degree=2)\n","  \n","# Create a Lasso object\n","lasso = Lasso()\n","  \n","# Define a dictionary of parameter\n","#values to search over\n","param_grid = {'lasso__alpha': [1e-4, 1e-3, 1e-2,\n","                               1e-1, 1, 5, 10, \n","                               20, 30, 40]}\n","  \n","# Create a pipeline that first applies \n","# polynomial features and then applies Lasso regression\n","pipeline = make_pipeline(poly, lasso)\n","  \n","# Create a GridSearchCV object with \n","#the pipeline and parameter grid\n","lasso_grid_search = GridSearchCV(pipeline,\n","                                 param_grid, \n","                                 scoring='r2', cv=3)\n","  \n","# Fit the GridSearchCV object to the training data\n","lasso_grid_search.fit(x_train_scaled, y_train)\n","\n","# Predict the target variable using\n","# the fitted model and the test data\n","y_pred = lasso_grid_search.predict(x_test_scaled)\n","\n","# Print the best parameter values and score\n","print('Best parameter values: ',\n","      lasso_grid_search.best_params_)\n","print('Best score: ',\n","      lasso_grid_search.best_score_)\n","\n","print(\"MAE = \",metrics.mean_absolute_error(y_test,y_pred))\n","print(\"MSE = \",metrics.mean_squared_error(y_test,y_pred))\n","print(\"RMSE = \",np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n","print(\"Score = \",metrics.r2_score(y_test,y_pred))\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNj64WVDb0MLTV5Cj/vCp2U","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
